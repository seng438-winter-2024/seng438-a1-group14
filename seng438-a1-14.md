# SENG 438 - Software Testing, Reliability, and Quality

## Lab. Report \#1 – Introduction to Testing and Defect Tracking

| Group: Group Number 14|
|-----------------|
| Santiago Fuentes |
| Hamza Amar |
| Huiying Zhen Zhen |
| Fardin Mahid |

### Table of Contents

(When you finish writing, update the following list using right click, then
“Update Field”)

[1 Introduction](#introduction)

[2 High-level description of the exploratory testing plan](#high-level-description-of-the-exploratory-testing-plan)

[3 Comparison of exploratory and manual functional testing](#comparison-of-exploratory-and-manual-functional-testing)

[4 Notes and discussion of the peer reviews of defect reports](#notes-and-discussion-of-the-peer-reviews-of-defect-reports)

[5 How the pair testing was managed and team work/effort was divided](#how-the-pair-testing-was-managed-and-team-workeffort-was-divided)

[6 Difficulties encountered, challenges overcome, and lessons learned](#difficulties-encountered-challenges-overcome-and-lessons-learned)

[7 Comments/feedback on the lab and lab document itself](#commentsfeedback-on-the-lab-and-lab-document-itself)

## Introduction

In this lab, we are testing an ATM system that has functions such as withdrawal, deposit, transfer and balance checking. This ATM system should let the user successfully login to their account with the correct card number and PIN. It should also let the user accurately withdraw, deposit and transfer the correct amounts and reflect an accurate balance inquiry report after each transaction.  

As a group, we learned that exploratory testing is the idea of getting to know the system to determine what functions need to be tested. We then will test those functions without predetermined test samples but instead randomly and find bugs that a user would interact with on a day-to-day basis. With this strategy, we wouldn’t have specific test pathways to follow but instead whatever bug we encounter when using the application, we will take note of that defect and report it.  

For manual scripted testing, we will use the set of test cases and their expected output for functions that need to be tested. These test cases will be about how the user will be interacting with the application so that if a bug is found, we can recreate the error and confirm that it is an actual bug. The test cases include the function being tested, the exact steps the user will take and then the expected result that the user should get. In the end, we will compile a table with all the results, manually go through each test case, and write down any results that differ from our expected results. Finally, we will do regression testing, by going through test cases once again for the new version of the code. This will help us not introduce any new bugs to the code. Also making sure that our new version fixes the bugs it was intended to fix.  

## High-level description of the exploratory testing plan

For the exploratory test cases we divided ourselves into two groups Santiago & Hamza and Huiying & Fardin, one person in each group tests the application and the other person writes the bug reports in azure DevOps. The high-level test plan for the exploratory testing that was followed is listed below.

Insert Card and successfully sign in

- Try the correct login information provided

- Try incorrect login information

- Try the correct login username but the incorrect pin

Withdraw the money and get the right money withdrawn and the correct bank balance after withdrawal for checking, savings and money market accounts

- Try withdrawing $20 and get the correct amount in your bank account and also the correct amount withdrawn

Deposit money and get the right money balance in the bank account after deposit for checking, savings and money market accounts

Transfer money between different types of accounts and get the correct balance for each account after the transaction

Get an accurate balance inquiry report for the checking, saving and money market accounts

## Comparison of exploratory and manual functional testing

Although disorganized by nature, exploratory testing shows how creative the testers are, giving them freedom on what and how to test. When doing exploratory testing, the tester tries to find all possible ways they can interact with the software. Doing this allows the tester to create different test ideas to be used to uncover faults in the software. Along with the understanding of how the software operates, the tester can fully understand the different aspects they need to test. Since this testing is how an average user would interact with the website, it is a quick way to find any immediate and application-breaking bugs.

On the other hand, manual scripted testing involves human interaction and no automation as well, but this one is more organized since test cases are provided for the tester to follow. When writing defect reports this is simpler since there is an order to follow and so the tester would only the faults that they are encountering. Knowledge of how the system fully works is not that necessary since there are instructions that describe how the test case runs.

In summary, exploratory testing gives the developer more freedom to study and verify how the application works, and centrally scripted testing helps the developer organize and verify each of the tests in systematic way.

## Notes and discussion of the peer reviews of defect reports

For the defect report we decided to use Azure DevOps platform which lets you tabulate and categorize different bugs related to an application as well as generate reports in excel for future development. In our case we decided to add each of the bugs with a corresponding tag, that is, exploratory type test as an example with another tag of the version of the program. Each of the bugs has a detailed explanation on how to be recreated.

For the exploratory phase of the testing, we found around 10 bugs and wrote defect reports for each of them using Azure DevOps. After testing and reviewing them we all agreed that they were detailed enough to replicate the bug or defect on our own so that when reviewing the application with a different version we would be able to track the bug. All the reports created by both groups had a similar format where we included description of the bug, procedure to replicate it, expected and actual outcomes, in addition, in the defect reports in Azure we added tags indicating whether they were part of the exploratory or scripted part of testing and the version that was used when tracking the bug. After doing regression testing, most of the bugs that were found were resolved and were no longer a bug.

## How the pair testing was managed and team work/effort was divided

We decided to divide the group into two pairs as follows:

Pair #1 (Santiago & Hamza): In charge of testing the system at start up and the first part of the system, inserting the initial amount of cash, inserting and validating the card.

Pair #2 (Huiying & Fardin): In charge of testing the atm system’s functionality of each of the transactions like withdrawal, deposit, transfer and check balance.

For the manual scripting testing we decide to divide the forty test cases into groups of 20 so each pair would have a chance to test and report the results in the Azure platform, each of the bugs got assigned a tag for the type of testing it was as well of the version of the program.

## Difficulties encountered, challenges overcome, and lessons learned

At the start of the lab, we encountered difficulties in understanding the documents and instructions and the types of testing we needed to complete. However, after some review and brainstorming, we understood the lab instructions better and started with exploratory testing and then moved on to the other two types of testing. The main takeaway from the lab for us was learning how to perform these three types of testing.

## Comments/feedback on the lab and lab document itself

The lab itself was a little bit overwhelming at the start since the lab session was disorganized and we were only given the lab document in GitHub. The instructions at times were ambiguous so we had to figure out what we had to do by asking for TAs assistance, as we progressed through the lab, we understood the instructions better and were able to complete the lab successfully.
